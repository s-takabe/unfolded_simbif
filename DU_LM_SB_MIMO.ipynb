{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11802a02-7d7a-4109-adb0-96218daf71b6",
        "outputId": "fec8c134-3c7b-44eb-905f-558978cdaee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from scipy.linalg import toeplitz\n",
        "\n",
        "device = torch.device('cuda') # 'cpu' or 'cuda'\n",
        "print(torch.__version__)\n",
        "\n",
        "\n",
        "## model parameters\n",
        "n=16 #trasmit antenna\n",
        "m=16 #receive antenna\n",
        "##\n",
        "N=2*n\n",
        "M=2*m\n",
        "\n",
        "## training paramete\n",
        "max_itr = 10 # max_itr\n",
        "bs = 2000 # mini batch size\n",
        "num_batch = 1000 # number of mini batches\n",
        "lr_adam = 5e-3 # learning rate of optimizer\n",
        "##\n",
        "\n",
        "## parameters for evauation of generalization error\n",
        "#total_itr=30 # total number of iterations (multiple number of \"itr\")\n",
        "sample = 1000\n",
        "bs_ = 2000 # number of samples\n",
        "##\n",
        "\n",
        "\n",
        "# SB settings\n",
        "eps = 1.0 #0.1\n",
        "T_max = max_itr #2000\n",
        "pump_SB = 1.0/(T_max*eps) #0.01 # pump coeff\n",
        "D_SB = 1. # delta\n",
        "xi_SB = 0.1 # xi_0"
      ],
      "id": "11802a02-7d7a-4109-adb0-96218daf71b6"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "504e28c8-a249-40c2-96a5-6b7ef03c186f",
        "outputId": "87593ac1-463d-4cf1-c360-b20b6ac383e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#_  n= 16 m= 16 max_itr= 10 bs= 2000 num_batch= 1000 learning_rate= 0.005\n",
            "-------------------\n",
            "snr= tensor(15.)\n",
            "loss0:0.00400887243449688 BER: tensor(0.0012, device='cuda:0')\n",
            "loss100:0.0007100640796124935 BER: tensor(0.0002, device='cuda:0')\n",
            "loss200:0.0015155017608776689 BER: tensor(0.0004, device='cuda:0')\n",
            "loss300:0.0005173049285076559 BER: tensor(0.0001, device='cuda:0')\n",
            "loss400:0.0011304032523185015 BER: tensor(0.0003, device='cuda:0')\n",
            "loss500:9.547865920467302e-05 BER: tensor(3.1250e-05, device='cuda:0')\n",
            "loss600:0.0005380481597967446 BER: tensor(0.0001, device='cuda:0')\n",
            "loss700:0.0004004885850008577 BER: tensor(9.3750e-05, device='cuda:0')\n",
            "loss800:0.00010085271787829697 BER: tensor(3.1250e-05, device='cuda:0')\n",
            "loss900:0.0007662293501198292 BER: tensor(0.0002, device='cuda:0')\n",
            "-----\n",
            " SNR: 15.0\n",
            "eps= Parameter containing:\n",
            "tensor([0.8615, 1.1523, 1.3482, 1.1030, 1.2161, 1.8658, 1.3472, 0.7327, 1.6134,\n",
            "        2.0544], device='cuda:0', requires_grad=True)\n",
            "beta= Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "xi= Parameter containing:\n",
            "tensor([1.1053], device='cuda:0', requires_grad=True)\n",
            "a= Parameter containing:\n",
            "tensor([1.], device='cuda:0', requires_grad=True)\n",
            "lam= tensor([4.3950], device='cuda:0', grad_fn=<PowBackward0>)\n",
            "train done\n",
            "SNR: 15.0 BER (generalization): 0.00013881237828172743\n"
          ]
        }
      ],
      "source": [
        "def x_gen(bs,n):\n",
        "    x = torch.rand(bs,n).to(device)\n",
        "    x[x<0.5] = -1\n",
        "    x[x>0.5] = 1\n",
        "    return x\n",
        "def y_gen(bs,m,x0,H,sigma_std):\n",
        "    return x0@H+ torch.normal(0.0, sigma_std*torch.ones(bs, m)).to(device)\n",
        "\n",
        "def trans_2_QUBO(H,y):\n",
        "    J = H@H.t() - torch.diag(torch.diagonal(H@H.t(),0))\n",
        "    h = -2*y@H.t()\n",
        "    lmax_2 = ((J*J).sum()/(N*(N-1)))**0.5 #estimated max. eig.\n",
        "    return J,h, 1.0/(2*N**0.5*lmax_2)\n",
        "\n",
        "def trans_2_QUBO_LMMSE(H,y,lam):\n",
        "    H_inv = torch.linalg.inv(H.t()@H+lam*torch.eye(M,device=device)) #dim:M*M\n",
        "    J = H@H_inv@H.t() - torch.diag(torch.diagonal(H@H_inv@H.t(),0))\n",
        "    h = -2*y@H_inv@H.t()\n",
        "    lmax_2 = ((J*J).sum()/(N*(N-1)))**0.5 #estimated max. eig.\n",
        "    return J,h, 1.0/(2*N**0.5*lmax_2)\n",
        "\n",
        "def BER(x,y):\n",
        "    z = torch.ones(x.size()).to(device)\n",
        "    z[torch.isclose(torch.sign(x),torch.sign(y))] = 0.\n",
        "    return z.sum()/(z.numel())\n",
        "\n",
        "seed_ =12\n",
        "torch.manual_seed(seed_)\n",
        "\n",
        "# QPSK\n",
        "def H_gen(m,n):\n",
        "    H_re = torch.normal(0.0, std=math.sqrt(0.5) * torch.ones(n,m))\n",
        "    H_im = torch.normal(0.0, std=math.sqrt(0.5) * torch.ones(n,m))  # sensing matrix\n",
        "    H = torch.cat((torch.cat((H_re,H_im),0),torch.cat((-1*H_im,H_re),0)),1)\n",
        "    H = H.to(device)\n",
        "    return H\n",
        "\n",
        "\n",
        "def est_SNR(snr,m,n):\n",
        "    sigma2 = (2*n/math.pow(10,snr/10.0))/2.0\n",
        "    sigma_std = math.sqrt(sigma2)\n",
        "    return sigma_std\n",
        "\n",
        "### DU\n",
        "class DU_dSB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DU_dSB,self).__init__()\n",
        "        self.eps = nn.Parameter( eps + 0.01 * torch.randn(max_itr,device=device))\n",
        "        self.lam = nn.Parameter(torch.ones(1,device=device))\n",
        "        self.xi = nn.Parameter(torch.ones(1,device=device))\n",
        "        self.beta = nn.Parameter(1.0*torch.ones(max_itr,device=device))\n",
        "\n",
        "    def Pump(self,t):\n",
        "        tsum = (self.eps).sum()\n",
        "        return t/tsum\n",
        "\n",
        "    def Softclamp(self,x):\n",
        "        si = nn.SiLU()\n",
        "        return si(10*(x+1))/10-si(10*(x-1))/10 -1\n",
        "\n",
        "    def dSB(self,k, q,p,t,eps,J,h,D_SB,pump_SB,xi_SB):\n",
        "        sq = q\n",
        "        DE_QUBO = 0.5 * h + sq@J\n",
        "        p_ = p - eps * ((D_SB-self.Pump(t)) * q + self.xi*xi_SB * DE_QUBO) #diff(q,Po)\n",
        "        q_ = q + (eps * D_SB) * p_ #diff(p,K)\n",
        "        q_2 = self.Softclamp(q_) #torch.clamp(q_, min=-1., max=1.)\n",
        "        p_ = p_ - p_ * torch.sigmoid(100* (torch.abs(q_)-1.01) )\n",
        "        # naively torch.heaviside(1-torch.abs(q_), torch.zeros(1,device=device)) but its derivative is unaveilabe\n",
        "        return q_2,p_\n",
        "\n",
        "    def forward(self, H,y,itr,bs):\n",
        "        J, h, xi_SB= trans_2_QUBO_LMMSE(H,y,self.lam**2)\n",
        "        q = torch.zeros(bs, N,device=device) # x\n",
        "        p = torch.zeros(bs, N,device=device) # y\n",
        "        q_traj = np.zeros([T_max, N]) # trajectory\n",
        "        p_traj = np.zeros([T_max, N]) # trajectory\n",
        "\n",
        "        p = 0.01*torch.randn(bs, N,device=device) # random init point\n",
        "\n",
        "        t = 0.0\n",
        "\n",
        "        for i in range(itr):\n",
        "            k = i % max_itr\n",
        "            t = t + self.eps[k]\n",
        "            q, p = self.dSB(k,q,p,t,self.eps[k],J,h,D_SB,pump_SB,xi_SB)\n",
        "            q_traj[i]=q[0,:].cpu().detach().numpy()\n",
        "            p_traj[i]=p[0,:].cpu().detach().numpy()\n",
        "\n",
        "        return q, p, q_traj, p_traj\n",
        "\n",
        "def train(snr):\n",
        "    #SNR\n",
        "    sigma_std = est_SNR(snr, m,n)\n",
        "\n",
        "    network = DU_dSB().to(device)  # generating an instance of TPG-detector\n",
        "    opt = optim.Adam(network.parameters(), lr=lr_adam )  # setting for optimizer\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    torch.manual_seed(1)\n",
        "    network.train()\n",
        "\n",
        "\n",
        "    print(\"-------------------\")\n",
        "    print(\"snr=\",snr)\n",
        "    for i in range(num_batch):#num_batch):\n",
        "        H = H_gen(m,n)\n",
        "        sol = x_gen(bs,N)\n",
        "        y = y_gen(bs,M,sol,H,sigma_std)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        x_hat,_,q_traj ,_= network(H,y,max_itr,bs)\n",
        "\n",
        "        loss = F.mse_loss(x_hat, sol) #squared_loss\n",
        "        loss.backward()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('loss{0}:{1}'.format(i,loss.data), \"BER:\", BER(sol,x_hat.sign())) #print_loss\n",
        "        opt.step()\n",
        "\n",
        "    print(\"-----\\n SNR:\",snr.item())\n",
        "    print(\"eps=\",network.eps)\n",
        "    print(\"beta=\",network.beta)\n",
        "    print(\"xi=\",network.xi)\n",
        "    print(\"lam=\",network.lam**2)\n",
        "    print(\"train done\")\n",
        "    return network\n",
        "\n",
        "# Generalization Error Evaluation\n",
        "def eval(network,snr):\n",
        "    ber_= 0.0\n",
        "    it = max_itr\n",
        "    sigma_std = est_SNR(snr, m,n)\n",
        "\n",
        "    for i in range(sample):\n",
        "        H = H_gen(m,n)\n",
        "        sol = x_gen(bs_,N)\n",
        "        y = y_gen(bs_,M,sol,H,sigma_std)\n",
        "        xx = torch.zeros(bs_,N,device=device)\n",
        "\n",
        "        res = 100*torch.ones(bs_,N,device=device)\n",
        "        x_hat,_,q_traj ,_= network(H,y, it,bs_)\n",
        "        res_ = (y-x_hat.sign()@H).norm(dim=1).view(bs_,1).repeat(1,N).view(bs_,N) # OK\n",
        "        xx[res_<res] = x_hat[res_<res]\n",
        "        res[res_<res] = res_[res_<res]\n",
        "        ber_ += BER(sol,xx.sign())\n",
        "\n",
        "    ber_ = ber_/sample\n",
        "    print(\"SNR:\",snr.item(),\"BER (generalization):\",ber_.item())\n",
        "\n",
        "\n",
        "# main part\n",
        "print(\"#_ \", \"n=\", n, \"m=\",m,\"max_itr=\", max_itr, \"bs=\",bs, \"num_batch=\", num_batch,\"learning_rate=\", lr_adam)\n",
        "\n",
        "for snr in torch.arange(15,16,2.5):\n",
        "    net = train(snr)\n",
        "    eval(net,snr)\n"
      ],
      "id": "504e28c8-a249-40c2-96a5-6b7ef03c186f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1t3JLm7olMW"
      },
      "outputs": [],
      "source": [],
      "id": "d1t3JLm7olMW"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}